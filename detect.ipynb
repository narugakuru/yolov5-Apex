{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from utils.torch_utils import select_device, smart_inference_mode\n",
    "from utils.general import (\n",
    "    LOGGER,\n",
    "    Profile,\n",
    "    check_file,\n",
    "    check_img_size,\n",
    "    check_imshow,\n",
    "    check_requirements,\n",
    "    colorstr,\n",
    "    cv2,\n",
    "    increment_path,\n",
    "    non_max_suppression,\n",
    "    print_args,\n",
    "    scale_boxes,\n",
    "    strip_optimizer,\n",
    "    xyxy2xywh,\n",
    ")\n",
    "from utils.dataloaders import (\n",
    "    IMG_FORMATS,\n",
    "    VID_FORMATS,\n",
    "    LoadImages,\n",
    "    LoadScreenshots,\n",
    "    LoadStreams,\n",
    ")\n",
    "from models.common import DetectMultiBackend\n",
    "from ultralytics.utils.plotting import Annotator, colors, save_one_box\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from utils.augmentations import letterbox\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from screenShot import screenshot\n",
    "from SendInput import mouse_xy\n",
    "\n",
    "\n",
    "FILE = Path(__file__).resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "\n",
    "def load_mode():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = DetectMultiBackend(\n",
    "        weights=\"./weights/yolov5n.pt\", device=device, dnn=False, data=False, fp16=True\n",
    "    )\n",
    "    return device, model"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@smart_inference_mode()\n",
    "def run(device, model):\n",
    "    # Load model\n",
    "    while True:\n",
    "        # 读取图片\n",
    "        # im = cv2.imread('data/images/bus.jpg')\n",
    "        im = screenshot()\n",
    "        im0 = im\n",
    "\n",
    "        # 处理图片\n",
    "        im = letterbox(im, (640, 640), stride=32, auto=True)[0]\n",
    "        im = im.transpose((2, 0, 1))[::-1]\n",
    "        im = np.ascontiguousarray(im)\n",
    "\n",
    "        # Run inference\n",
    "        im = torch.from_numpy(im).to(model.device)\n",
    "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "\n",
    "        # 推理\n",
    "        start = time.time()\n",
    "        pred = model(im, augment=False, visualize=False)\n",
    "        # 只检测0：person\n",
    "        pred = non_max_suppression(\n",
    "            pred, conf_thres=0.6, iou_thres=0.45, classes=0, max_det=1000\n",
    "        )\n",
    "        end = time.time()\n",
    "        # print(f'推理时间：{end - start}s')\n",
    "\n",
    "        # Process predictions\n",
    "        for i, det in enumerate(pred):  # per image\n",
    "            # 画框\n",
    "            annotator = Annotator(im0, line_width=1)\n",
    "\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                distance_list = []\n",
    "                target_list = []\n",
    "                # 画框转化为原图\n",
    "                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):  # 处理每个目标的信息\n",
    "                    # line = (cls, *xywh, conf)  # label format\n",
    "                    xywh = (\n",
    "                        (xyxy2xywh(torch.tensor(xyxy).view(1, 4))).view(-1).tolist()\n",
    "                    )  # normalized xywh\n",
    "                    # print(xywh, line)\n",
    "                    X = int(xywh[0] - 320)\n",
    "                    Y = int(xywh[1] - 320)\n",
    "                    distance = math.sqrt(X**2 + Y**2)\n",
    "                    annotator.box_label(\n",
    "                        xyxy,\n",
    "                        label=f\"[{int(cls)}Distance:{round(distance,2)}]\",\n",
    "                        color=(99, 88, 201),\n",
    "                        txt_color=(201, 88, 99),\n",
    "                    )\n",
    "                    # 存储每个目标的信息\n",
    "                    distance_list.append(distance)\n",
    "                    target_list.append(xywh)\n",
    "                    print(distance)\n",
    "                target_info = target_list[distance_list.index(min(distance_list))]\n",
    "                # print(f'偏移:{move_X,move_Y}')\n",
    "                x, y = int(target_info[0], target_info[1])\n",
    "                mouse_xy(x, y)\n",
    "\n",
    "            im0 = annotator.result()\n",
    "            cv2.imshow(\"window\", im0)\n",
    "            cv2.waitKey(1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fc091269bf17dc35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device, model = load_mode()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "eafeea226b5678ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run(device, model)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "371e60e935bb0a6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
